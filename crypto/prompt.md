现在我将要对`crypto`文件夹下，进行编程实现：

1、我会定期下载最新的买入成交记录，文件样例如`汇出历史成交-2025-09-18 10_09_11.xlsx`，字段含义如下:
```
{
    'date':'交易时间',
    'pair':'交易链路',
    'type':'交易类型',
    'base_asset':'买入币种',
    'price':'成交价格',
    'amount':'成交量',
    'total':'成交金额'
}
```

2、需求说明：
- 进行数据归并处理，将同一时间（到秒）产生的订单且交易链路相同的情况视为同一单（因为系统撮合交易的原因，会有零碎散单）, 归并时需要根据字段类型判断是否求和(先看看你聪明程度吧， 有难度后面再具体讨论)

- 需要保留字段和上述字段一致,文件生成格式为excel，文件名称为：`crypto-invest-log.xlsx`，按年进行sheet划分

- 执行脚本需要提示需要处理订单的起止日期，考虑到后面会有不定期的处理需求，如果有跨年的数据，需要写入到不同的sheet里面

- 保留excel的第一个sheet为统计汇总的图表，目前统计需求如下：汇总可以选择年份、买入币种，按月的成交额汇总


3、对话与决策记录（2025-09-19）

- 问题1：若导入的多个 Excel 存在相同日期区间，程序如何处理？
  - 结论：程序会合并所有来源后再按“到秒 + 交易链路(pair) + 交易类型(type) + 基币(base_asset)”聚合。同一订单若在多个文件重复出现，会在聚合前被视为多行并累加数量与金额，价格为加权价（total_sum/amount_sum）。无重复订单则结果正常。

- 问题2：从健壮性与使用场景出发，是否需要去重？
  - 权衡：
    - 加去重有助于避免重复累计、保证结果稳定；
    - 风险在于无 trade_id，仅能用字段组合近似去重，极端情况下可能误判完全相同值的两笔独立成交。
  - 决策：采用“优先级2”方案，启用可配置的精确字段组合去重，默认开启，可关闭。

- 实施变更：
  - 新增命令行参数：`--dedupe {on|off}`，默认 `on`。
  - 去重策略：在聚合前，基于以下字段做精确去重：
    - `['date','pair','type','base_asset','price','amount','total']`
  - 去重位置：读取与类型规范化后、按日期筛选后、聚合前。
  - 可观测性：打印去重前后行数与移除数量统计。

- 使用示例：
  - 默认开启去重：
    ```bash
    python crypto/process_trades.py --start 2024-01-01 --end 2024-12-31
    ```
  - 关闭去重：
    ```bash
    python crypto/process_trades.py --dedupe off
    ```

